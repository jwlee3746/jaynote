---
title: "[머신러닝] MLE 기술 면접 대비 질문 - 수학, 통계"
excerpt: "수학, 통계, 머신러닝, 딥러닝 기술 면접을 위한 문제와 답변 해보기" # 주요 내용

categories:
  - Machine Learning
tags:
  - [Machine Learning]

permalink: /Machine Learning/MLE기술면접대비질문/

toc: true
toc_sticky: true

# date: 2024-05-21
# last_modified_at: 2024-05-20

author_profile: true
search: true
use_math: true
---

## 고유값(eigenvalue)과 고유벡터란?
<div align="center">
$$ A \mathbf{v} = \lambda \mathbf{v} $$
</div>

Nx1 벡터 v에 대해 정방행렬 A (NxN)로 선형 변환시켰을 때, 방향이 유지되는 경우 v를 고유벡터, $ \lambda $를 고유값이라고 함.   
고유값은 특성 방정식 $ det(A - \lambda I) = 0 $을 풀어 구함.   
정방 행렬이 아닌 mxn 행렬을 분해하는 SVD, 차원 축소 기법인 PCA로 확장.

## 확률 변수(Random Variable)란?

**실험이나 관찰에서 시행의 결과에 따라 값이 결정되는 변수**.

- 이산 확률 변수(Discrete Random Variable):   
  - 특정한 값을 가질 수 있으며, 그 값들을 세는 것이 가능.   
  - 예: 주사위를 굴렸을 때 나오는 눈의 수 1~6은 각 각 이산 확률 변수의 값

- 연속 확률 변수(Continuous Random Variable):
  - 특정 구간 내의 모든 실수 값을 가질 수 있으며, 그 값들을 세는 것이 불가능.   
  - 예: 특정 지역의 온도, 사람의 키

## 확률 분포(Probablity Distribution)란?

**확률 변수의 값이 나타날 확률**

- 이산 확률 분포: 확률 질량 함수(probability mass function, PMF)로 나타내며, 각 가능한 값에 대해 그 값이 나타날 확률을 제공합.

<div align="center">
$$ P(X \in B) = \sum_{x \in B} p_X(x) $$
</div>

- 연속 확률 분포: 확률 밀도 함수(probability density function, PDF)로 나타내며, 특정 구간 내에서 값이 나타날 확률을 제공합. **PDF의 적분은 그 구간에서 확률**.

<div align="center">
$$ P(X \in B) = \int_B f_X(x) \, dx $$
</div>

- 기대값(Expected Value): 확률 변수의 평균적인 값을 나타내며, 각 값에 그 값이 나타날 확률을 곱한 후 모두 더한 값.

- 분산(Variance): 확률 변수 값들이 기대값을 중심으로 얼마나 퍼져 있는지를 나타내는 척도.

## Bayes 정리란?

두 가지 맥락에서 이해할 수 있다.

### 역확률 문제   
<div align="center">
$$ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} $$
</div>

**어떤 사건이 일어난 후 각 원인들의 조건부 확률을 구하는 것**

문제: 병A를 앓고 있는 지를 판정하는 양성 판정 정확도가 90%인 검사지가 있을 때, 어떤 사람이 양성 판정을 받았다면(사건) 병 A를 앓고 있을(원인) 확률이 90%일까? X

양성판정 정확도는 $ P(양성\|A) = 0.9 $이고, 구하고자 하는 것은 $ P(A\|양성) $이다.   
질병이 전세계 1% 확률로 발현되고 검사의 음성 판정 정확도($ P(\text{음성} \| \neg A) $)가 똑같이 90% 라면,

<div align="center">
$$ P(A|양성) = \frac{P(양성|A) \cdot P(A)}{P(양성)} \\= \frac{P(양성|A) \cdot P(A)}{P(\text{양성} | A) \cdot P(A) + P(\text{양성} | \neg A) \cdot P(\neg A)} \\= \frac{0.9 \times 0.01}{0.108} \approx 0.0833$$
</div>
<br>

### 데이터를 이용한 사후확률의 업데이트
<div align="center">
$$ P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)} $$
$$ (H: Hypothesis, E: Evidence)$$
</div>

**증거를 본 후 가설에 대한 귀하의 믿음(사후확률)을 구하는 것**
- 과학자: 새로운 데이터가 모델을 검증하거나 무효화하는 정도를 분석
- 프로그래머: 기계의 믿음을 명시적이고 수치적으로 모델링

{% include video id="HZGCoVF3YvM" provider="youtube" %}

**중요한 것은, 증거(데이터)를 이용해 가설에 대한 믿음을 '결정'하는 것이 아니라 '업데이트'하는 것임.**

## Naive Bayes

베이즈 정리의 일반화.   
E가 여러 개의 사건으로 이루어진 복잡한 사건일 때 베이즈 정리는 다음과 같이 표현.

<div align="center">
$$ P(H|E) = P(H|E_1 \cap E_2 \cap \cdots \cap E_n) = \frac{P(E_1 \cap E_2 \cap \cdots \cap E_n|H) \cdot P(H)}{P(E)} $$
</div>

이 때, 각 하위 사건이 서로 독립이라는 naive한 가정을 두어 계산을 편하게 함.

<div align="center">
$$ P(H|E_1 \cap E_2 \cap \cdots \cap E_n) = \frac{P(E_1|H) \cdot P(E_2|H) \cdots P(E_n|H) \cdot P(H)}{P(E)} $$
</div>
