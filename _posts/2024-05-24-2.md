---
title: "[머신러닝] MLE 기술 면접 대비 질문 - 수학, 통계"
excerpt: "수학, 통계, 머신러닝, 딥러닝 기술 면접을 위한 문제와 답변 해보기" # 주요 내용

categories:
  - Machine Learning
tags:
  - [Machine Learning]

permalink: /Paper/MLE기술면접대비질문/

toc: true
toc_sticky: true

# date: 2024-05-21
# last_modified_at: 2024-05-20

author_profile: true
search: true
use_math: true
---

### 고유값(eigenvalue)과 고유벡터란?
<div align="center">
$$ A \mathbf{v} = \lambda \mathbf{v} $$
</div>

Nx1 벡터 v에 대해 정방행렬 A (NxN)로 선형 변환시켰을 때, 방향이 유지되는 경우 v를 고유벡터, $ \lambda $를 고유값이라고 함.   
고유값은 특성 방정식 $ det(A - \lambda I) = 0 $을 풀어 구함.   
정방 행렬이 아닌 mxn 행렬을 분해하는 SVD, 차원 축소 기법인 PCA로 확장.

### 확률 변수(Random Variable)란?

**실험이나 관찰에서 시행의 결과에 따라 값이 결정되는 변수**.

- 이산 확률 변수(Discrete Random Variable):   
  - 특정한 값을 가질 수 있으며, 그 값들을 세는 것이 가능.   
  - 예: 주사위를 굴렸을 때 나오는 눈의 수 1~6은 각 각 이산 확률 변수의 값

- 연속 확률 변수(Continuous Random Variable):
  - 특정 구간 내의 모든 실수 값을 가질 수 있으며, 그 값들을 세는 것이 불가능.   
  - 예: 특정 지역의 온도, 사람의 키

### 확률 분포(Probablity Distribution)란?

**확률 변수의 값이 나타날 확률**

- 이산 확률 분포: 확률 질량 함수(probability mass function, PMF)로 나타내며, 각 가능한 값에 대해 그 값이 나타날 확률을 제공합.

<div align="center">
$$ P(X \in B) = \sum_{x \in B} p_X(x) $$
</div>

- 연속 확률 분포: 확률 밀도 함수(probability density function, PDF)로 나타내며, 특정 구간 내에서 값이 나타날 확률을 제공합. **PDF의 적분은 그 구간에서 확률**.

<div align="center">
$$ P(X \in B) = \int_B f_X(x) \, dx $$
</div>

- 기대값(Expected Value): 확률 변수의 평균적인 값을 나타내며, 각 값에 그 값이 나타날 확률을 곱한 후 모두 더한 값.

- 분산(Variance): 확률 변수 값들이 기대값을 중심으로 얼마나 퍼져 있는지를 나타내는 척도.

### Bayes 정리란?
<div align="center">
$$ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} $$
</div>

**조건부 확률(사후확률)을 구하는 공식**   
두 가지 맥락에서 이해할 수 있다.

1. 역확률 문제   
  예시) 병A를 앓고 있는 지를 판정하는 양성 판정 정확도가 90%인 검사지가 있을 때, 어떤 사람이 양성 판정을 받았다면 병 A를 앓고 있을 확률이 90%일까? X
  
  답) 양성판정 정확도는 $ P(양성|A) = 0.9 $ 이고, 구하고자 하는 것은 $ P(A|양성) $이다.
  <!-- 질병이 전세계 1% 확률로 발현되고 검사의 음성 판정 정확도($ P(\text{음성} | \neg A) $)가 똑같이 90% 라면, -->
  
  <div align="center">
  $$ P(A|양성) = \frac{P(양성|A) \cdot P(A)}{P(양성)} \\= \frac{P(양성|A) \cdot P(A)}{P(\text{양성} | A) \cdot P(A) + P(\text{양성} | \neg A) \cdot P(\neg A)} \\= \frac{0.9 \times 0.01}{0.108} \approx 0.0833$$
  </div>
   
2. 데이터를 이용한 사후확률 추정 (나이브 베이지안)
  
  

<!-- <div align="center">
$$ PE(pos, 2i+1) = \cos\left(\frac{pos}{10000^{\frac{2i}{d_{model}}}}\right) $$
</div> -->
