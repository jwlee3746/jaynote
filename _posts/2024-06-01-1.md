---
title: "[Generative Model] Variational Inference (변분 추론)"
excerpt: "VAE, diffusion에 적용되는 variational inference(bayes)에 대해 정리한다." # 주요 내용

categories:
  - Computer Vision
  - Generative Model
  - Machine Learning
tags:
  - [Computer Vision, Generative Model, Machine Learning]

permalink: /CV/VI/

toc: true
toc_sticky: true

date: 2024-06-01
# last_modified_at: 2024-05-20

author_profile: true
search: true
use_math: true
---

Variational Inference (VI)는 베이지안 추론에서 사후 확률 분포(posterior distribution)를 근사하는 방법 중 하나입니다. VI는 사후 확률 분포를 직접 계산하기 어려울 때, 보다 간단한 확률 분포를 사용하여 사후 확률 분포를 근사합니다.
VI의 기본 아이디어는 다음과 같습니다:

근사하고자 하는 사후 확률 분포를 $p(\mathbf{z}|\mathbf{x})$라고 합시다. 여기서 $\mathbf{z}$는 잠재 변수(latent variable)이고, $\mathbf{x}$는 관측 변수(observed variable)입니다.
$q_{\phi}(\mathbf{z})$를 사후 확률 분포의 근사 분포(approximating distribution)라고 합시다. 이 분포는 변분 분포(variational distribution)라고도 하며, $\phi$는 이 분포의 매개변수입니다.
VI의 목적은 KL divergence $D_{KL}(q_{\phi}(\mathbf{z})|p(\mathbf{z}|\mathbf{x}))$를 최소화하는 것입니다. 이는 $q_{\phi}(\mathbf{z})$가 $p(\mathbf{z}|\mathbf{x})$와 가능한 한 가깝도록 만드는 것을 의미합니다.

<div align="center">
$$ \min_{\phi} D_{KL}(q_{\phi}(\mathbf{z})|p(\mathbf{z}|\mathbf{x})) 
$$
</div>

그러나 $ p(\mathbf{z}\|\mathbf{x}) $를 직접 계산하기 어렵기 때문에, VI는 Evidence Lower Bound (ELBO)를 최대화하는 것으로 문제를 변형합니다.

<div align="center">
$$ \max_{\phi} \mathcal{L}(\phi) = \mathbb{E}{q{\phi}(\mathbf{z})}[\log p(\mathbf{x}, \mathbf{z}) - \log q_{\phi}(\mathbf{z})]
$$
</div>

ELBO $\mathcal{L}(\phi)$를 최대화하는 것은 KL divergence를 최소화하는 것과 동등합니다.

VI에서는 일반적으로 Stochastic Gradient Descent (SGD)를 사용하여 ELBO를 최대화합니다. 이를 위해 $q_{\phi}(\mathbf{z})$에서 샘플을 추출하고, Monte Carlo 방법을 사용하여 기대값을 근사합니다.

```python
def elbo(phi, x):
    z = q_phi.sample()  # q_phi(z)에서 샘플 추출
    return log_p(x, z) - log_q_phi(z)  # ELBO 계산

# SGD를 사용하여 ELBO 최대화
phi = init_phi()
for _ in range(num_iterations):
    phi_grad = grad(elbo(phi, x))  # ELBO의 gradient 계산
    phi = phi + learning_rate * phi_grad  # 매개변수 업데이트
```
위 코드에서 q_phi는 $q_{\phi}(\mathbf{z})$를 나타내는 확률 분포 객체이고, log_p와 log_q_phi는 각각 $\log p(\mathbf{x}, \mathbf{z})$와 $\log q_{\phi}(\mathbf{z})$를 계산하는 함수입니다. grad는 주어진 함수의 gradient를 계산하는 함수입니다.